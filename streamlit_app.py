import os
import streamlit as st
import tempfile

from langchain.text_splitter import RecursiveCharacterTextSplitter  
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.tools.retriever import create_retriever_tool
from langchain.prompts import ChatPromptTemplate
from langchain.agents import create_tool_calling_agent, AgentExecutor

# --------------------------------------------------------------------
# 1. Web Search Tool
# --------------------------------------------------------------------
def search_web():
    return TavilySearchResults(k=6, name="web_search")


# --------------------------------------------------------------------
# 2. PDF Tool
# --------------------------------------------------------------------
# ê³ ì • PDF tool ì¶”ê°€
def load_fixed_pdf():
    pdf_path = "data/í‚¤ì˜¤ìŠ¤í¬(ë¬´ì¸ì •ë³´ë‹¨ë§ê¸°) ì´ìš©ì‹¤íƒœ ì¡°ì‚¬.pdf"   
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(documents)

    vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())
    retriever = vector.as_retriever(search_kwargs={"k": 5})

    retriever_tool = create_retriever_tool(
        retriever,
        name="pdf_search",
        description="This tool gives you direct access to the reference PDF document."
    )
    return retriever_tool



# --------------------------------------------------------------------
# 3. Agent + Prompt êµ¬ì„±
# --------------------------------------------------------------------
def build_agent(tools):
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "ë‹¹ì‹ ì€ ì›°ì‹œì½”ê¸° ì´ˆë³´ ì–‘ìœ¡ìë“¤ì„ ë•ëŠ” ìœ ìš©í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
         "ë¨¼ì € í•­ìƒ 'pdf_search'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
         "ìµœëŒ€í•œ pdfì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ë‚´ìš©ì„ ì°¸ê³ í•˜ì„¸ìš”. "
         "ë§Œì•½ 'pdf_search'ì—ì„œ ê´€ë ¨ëœ ê²°ê³¼ê°€ ì—†ë‹¤ë©´, ì¦‰ì‹œ `web_search`ë§Œ í˜¸ì¶œí•˜ì„¸ìš”. "
         "ë‘ ë„êµ¬ë¥¼ ì ˆëŒ€ ì„ì–´ì„œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš” "
         "ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ë©°, ì´ëª¨ì§€ë¥¼ í¬í•¨í•˜ì„¸ìš”."
         "ê·¸ë¦¬ê³  ì›°ì‹œì½”ê¸°ê°€ ë§í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë§¨ ì²˜ìŒ ë§ì—ëŠ” 'ì•ˆë…•í•˜ì„¸ìš” ì£¼ì¸ë‹˜!'ìœ¼ë¡œ ì‹œì‘í•˜ê³ , ì›°ì‹œì½”ê¸°ëŠ” 'ì €ëŠ”'ì´ëŸ° ì‹ìœ¼ë¡œ 1ì¸ì¹­ìœ¼ë¡œ ë§í•˜ê³ , ë§¨ ë§ˆì§€ë§‰ ë§ì— 'ì €ì— ëŒ€í•´ ë” ì§ˆë¬¸í•´ì£¼ì„¸ìš”, ì•Œì•Œ!'ì„ ë¶™ì´ë„ë¡ í•˜ì„¸ìš”"),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}")
    ])

    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True)

    return agent_executor


# --------------------------------------------------------------------
# 4. Agent ì‹¤í–‰ í•¨ìˆ˜ (íˆ´ ì‚¬ìš© ë‚´ì—­ ì œê±°)
# --------------------------------------------------------------------
def ask_agent(agent_executor, question: str):
    result = agent_executor.invoke({"input": question})
    answer = result["output"]

    # intermediate_stepsì—ì„œ ë§ˆì§€ë§‰ë§Œ ê°€ì ¸ì˜¤ê¸°
    if result.get("intermediate_steps"):
        last_action, _ = result["intermediate_steps"][-1]
        answer += f"\n\nì¶œì²˜:\n- Tool: {last_action.tool}, Query: {last_action.tool_input}"

    return f"ë‹µë³€:\n{answer}"


# --------------------------------------------------------------------
# 5. Streamlit ë©”ì¸
# --------------------------------------------------------------------
def main():
    st.set_page_config(page_title="ì›°ì‹œì½”ê¸° ì‚¬ìš©ë²•", layout="wide", page_icon="ğŸ¤–")
    st.image('data/kibo.jpg', width=800)
    st.markdown('---')
    st.title("ì•ˆë…•í•˜ì„¸ìš”! ì•Œì•Œ~ RAG + Webì„ í™œìš©í•œ 'ì›°ì‹œì½”ê¸° AI ë¹„ì„œ' ì…ë‹ˆë‹¤")  

    with st.sidebar:
        openai_api = st.text_input("OPENAI API í‚¤", type="password")
        tavily_api = st.text_input("TAVILY API í‚¤", type="password")
        pdf_docs = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", accept_multiple_files=True)

    if openai_api and tavily_api:
        os.environ['OPENAI_API_KEY'] = openai_api
        os.environ['TAVILY_API_KEY'] = tavily_api

        # ê³ ì • PDF tool ì¶”ê°€
        tools = [search_web(), load_fixed_pdf()]
        agent_executor = build_agent(tools)

        if "messages" not in st.session_state:
            st.session_state["messages"] = []

        user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

        if user_input:
            response = ask_agent(agent_executor, user_input)
            st.session_state["messages"].append({"role": "user", "content": user_input})
            st.session_state["messages"].append({"role": "assistant", "content": response})

        for msg in st.session_state["messages"]:
            st.chat_message(msg["role"]).write(msg["content"])

    else:
        st.warning("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
